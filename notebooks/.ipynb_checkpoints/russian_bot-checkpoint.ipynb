{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "import utils\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = 800\n",
    "import numpy as np\n",
    "import gensim\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "from keras.models import Sequential, optimizers\n",
    "from keras.layers import Dense\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/tweets/tweets.csv', low_memory=False, header=0, encoding = \"ISO-8859-1\")\n",
    "data['BotType']=data['BotType'].apply(lambda x:0 if x== 'Traditional' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "data.loc[:,'text'] = utils.clean_tweets(data.loc[:,'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitigate class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Undersample traditional bots\n",
    "a = data[data['BotType']==0].sample(frac=.2)\n",
    "b = data[data['BotType']==1]\n",
    "data  = pd.concat([a,b],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.loc[:,'text'], data['BotType'], test_size=0.2, random_state=321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf-idf conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', token_pattern='[\\w]+', ngram_range=(1,2))\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_choice = 'lstm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf_choice == 'xgb':\n",
    "    # xgboost classifier\n",
    "    clf = XGBClassifier(n_jobs=4)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "elif clf_choice == 'mlp':\n",
    "    # Simply multilayer perceptron\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=x_train.shape[1], activation='relu'))\n",
    "#     model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(x_train, y_train, epochs=5, batch_size=20, verbose=1)\n",
    "#     model.fit(x_train, y_train, epochs=5, batch_size=20, verbose=0, callbacks=[TQDMNotebookCallback()])\n",
    "    # predict the test set\n",
    "    y_pred = model.predict_classes(x_test)\n",
    "elif clf_choice == 'lstm':\n",
    "    # LSTM implementation\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=x_train.shape[1], output_dim=32))\n",
    "    model.add(LSTM(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt_params = optimizers.RMSprop(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt_params, metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train, epochs=2, batch_size=100, verbose=0, callbacks=[TQDMNotebookCallback()])\n",
    "    y_pred = model.predict_classes(x_test)\n",
    "    \n",
    "    \n",
    "print classification_report(y_test, y_pred)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clf_choice == 'xgb':\n",
    "    idx = np.argsort(clf.feature_importances_)[::-1]\n",
    "    most_freq_words = [tfidf.get_feature_names()[x] for x in idx[:100]]\n",
    "    trace = go.Scatter(x= most_freq_words, y=np.sort(clf.feature_importances_)[::-1][:50])\n",
    "    layout = dict(title='Feature Importance', xaxis=dict(title='Top 100 Words'), yaxis=dict(title='Feature Weights'))\n",
    "    fig = dict(data=[trace], layout=layout)\n",
    "    plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code that does word2vec, did not work well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = gensim.models.Word2Vec(x_train, workers=4, size=300)\n",
    "# w2v = dict(zip(model.wv.index2word, model.wv.vectors))\n",
    "# temp = MeanEmbeddingVectorizer(w2v)\n",
    "# temp.fit(x_train)\n",
    "# x_train = temp.transform(x_train)\n",
    "# x_test = temp.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling technique, did not do as well as undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train, y_train = RandomOverSampler().fit_sample(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
